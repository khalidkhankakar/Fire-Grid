import { DataAPIClient } from "@datastax/astra-db-ts";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
import "dotenv/config";
import { createGoogleGenerativeAI } from "@ai-sdk/google";
import sampleData from "./firegird.json" with { type: "json" };

// Initialize Google Generative AI SDK
const google = createGoogleGenerativeAI({
  apiKey: process.env.GOOGLE_API_KEY,
});

// Initialize Datastax client
const client = new DataAPIClient(process.env.ASTRA_DB_APPLICATION_TOKEN);
const db = client.db(process.env.ASTRA_DB_API_ENDPOINT, {
  namespace: process.env.ASTRA_DB_NAMESPACE,
});

// Initialize text splitter
const splitter = new RecursiveCharacterTextSplitter({
  chunkSize: 1000,
  chunkOverlap: 200,
});

// Create collection in Datastax
const createCollection = async () => {
  try {
    await db.createCollection("firegrid", {
      vector: {
        dimension: 512, // Adjust to match Google's embedding dimensions
      },
    });
    console.log("Collection created successfully");
  } catch (error) {
    console.log("Collection already exists or error occurred:", error);
  }
};

// Load data into the collection
const loadData = async () => {
  const collection = await db.collection("firegrid");

  for await (const { id,info, description } of sampleData.data) {
    const chunks = await splitter.splitText(description); // Split text into smaller chunks
    let i = 0;

    for await (const chunk of chunks) {
      try {
        // Generate embeddings using Google Generative AI
        const embeddingModel = google.textEmbeddingModel("text-embedding-004", {
          outputDimensionality: 512, // Optional, ensures consistency with the collection
        });

        const {embeddings: [embeddings]} = await embeddingModel.doEmbed({ values: [chunk] });


        // Insert the vector and metadata into the collection
        await collection.insertOne({
          document_id: id,
          $vector: embeddings, // Use the embedding generated by Google
          info,
          description: chunk,
        });

        i++;
      } catch (error) {
        console.error(`Error processing chunk ${i}:`, error);
      }
    }
  }

  console.log("Data added successfully");
};

// Execute the script
createCollection()
  .then(() => loadData())
  .catch((error) => console.error("Error during execution:", error));
